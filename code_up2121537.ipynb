{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 2 images\n",
    "from IPython.display import Image, display\n",
    "\n",
    "img_paths = ['/home/up2121537/kaggle/steel_detection/test/000ccc2ac.jpg',\n",
    "            '/home/up2121537/kaggle/steel_detection/test/0000f269f.jpg']\n",
    "display(Image(img_paths [0]))\n",
    "display(Image(img_paths [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "lables = pd.read_csv(\"/home/up2121537/kaggle/steel_detection/traincsv/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the CSV file\n",
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of the class labels in a dataset\n",
    "lables[\"ClassId\"].value_counts().plot(kind = 'bar')\n",
    "lables[\"ClassId\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the images into classes\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import shutil \n",
    "import os \n",
    "import sys\n",
    "\n",
    "lables = pd.read_csv(\"/home/up2121537/kaggle/steel_detection/traincsv/train.csv\")\n",
    "\n",
    "train_dir = '/home/up2121537/kaggle/steel_detection/train'\n",
    "Class = '/home/up2121537/kaggle/steel_detection/Class'\n",
    "\n",
    "if not os.path.exists(Class):\n",
    "    os.mkdir(Class)\n",
    "    \n",
    "for row in lables.itertuples(): \n",
    "    ImageId = row.ImageId\n",
    "    ClassId = row.ClassId\n",
    "    \n",
    "    if not os.path.exists(Class + str(ClassId)):\n",
    "        os.mkdir(Class + str(ClassId))\n",
    "        \n",
    "    src_path = train_dir + '/' + ImageId \n",
    "    dst_path = Class + str(ClassId) + '/' + ImageId \n",
    "    \n",
    "    try: \n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        print(\"successful\")\n",
    "    except IOError as e: \n",
    "        print ('Unable to copy file {} to {}'\n",
    "               .format(src_path, dst_path))\n",
    "    except:\n",
    "        print('When try copy file {} to {}, unexpected error: {}'\n",
    "              .format(src_path, dst_path, sys.exc_info()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os        \n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 using a pretrainde model(Resnet 50) with 10 epochs\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the model architecture\n",
    "base_model = ResNet50(input_shape=(120, 120, 3), include_top=False, weights='imagenet')\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Create an instance of ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Define the data directories\n",
    "data_dir = '/home/up2121537/kaggle/steel_detection/data/Class'\n",
    "\n",
    "# Flow the data from the directories and apply data augmentation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot the training and validation accuracy and loss\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(10)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2 just 3 CNN layers , the size of kernel is (3,3) with 10 epoches and using data augmentation\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(120, 120, 3)),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling2D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Create an instance of ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Define the data directories\n",
    "data_dir = '/home/up2121537/kaggle/steel_detection/data/Class'\n",
    "\n",
    "# Flow the data from the directories and apply data augmentation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot the training and validation accuracy and loss\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(10)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples//test_generator.batch_size)\n",
    "\n",
    "print('Test Acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3\n",
    "# the most accurate model with 3 CNN layers with maxpooling and Dropout , the size of kernel is (5,5) with 50 epoches and using data augmentation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), strides=(2, 2) ,activation='relu', input_shape=(120, 120, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Dropout(rate=0.15),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), strides=(2, 2) ,activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Dropout(rate=0.1),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), strides=(2, 2),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    keras.layers.Dropout(rate=0.10),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Create an instance of ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "# Define the data directories\n",
    "data_dir = '/home/up2121537/kaggle/steel_detection/data/Class'\n",
    "\n",
    "# Flow the data from the directories and apply data augmentation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
    "    epochs=50,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot the training and validation accuracy and loss\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(50)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(120, 120),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples//test_generator.batch_size)\n",
    "\n",
    "print('Test Acc:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
